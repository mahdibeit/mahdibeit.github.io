# Site
repository: sproogen/resume-theme
favicon: images/favicon.ico

# Content configuration version
version: 2

# Personal info
name: Mahdi Beitollahi
title: Machine Learning Research Scientist
#email: beitollahi.mahdi
#website: www.github.com/sproogen/resume-theme

# Dark Mode (true/false/never)
darkmode: never

# Social links
#twitter_username: facespics
github_username:  mahdibeit
# stackoverflow_username: "00000001"
# dribbble_username: jekyll
# facebook_username: jekyll
# flickr_username: jekyll
#instagram_username: jameswgrant
#linkedin_username: jameswgrant
# xing_username: jekyll
# pinterest_username: jekyll
#youtube_username: globalmtb
# googleplus_username: +jekyll
# orcid_username: 0000-0000-0000-0000

# Additional icon links
additional_links:
- title: Google Scholar
  icon: fa fa-graduation-cap
  url: https://scholar.google.ca/citations?user=HdvxM78AAAAJ&hl=en
# - title: another link
#   icon: font awesome brand icon name (eg. fab fa-twitter) (https://fontawesome.com/icons?d=gallery&m=free)
#   url: Link url (eg. https://google.com)

# Google Analytics and Tag Manager
# Using more than one of these may cause issues with reporting
# gtm: "GTM-0000000"
# gtag: "UA-00000000-0"
# google_analytics: "UA-00000000-0"

# About Section
# about_title: About Me
about_profile_image: images/profile.jpg
about_content: | # this will include new lines to allow paragraphs
  Hi, my name is Mahdi and I'm a machine learning research scientist at <mark>Huawei</mark> Noah's Ark Lab Montreal. I have +4 years of experience in industry and academia. I have delivered end-to-end AI products for computer vision, bio-medical sensors, and audio processing to three companies. My research focuses on the implementation of distributed machine learning and privacy-preserving machine learning. 


content:
  - title: Projects # Title for the section
    layout: list # Type of content section (list/text)
    content:
      - layout: left #top-middle
        title: Shortube.site
        link: http://Shortube.site
        sub_title: personal project
        link_text: Link to site
        additional_links:
          # - title:  
          #   icon: fab fa-github
          #   url: 
        #quote: >
          #This is probably one of the greatest apps ever created, if you don't agree you're probably wrong.
        description: | # this will include new lines to allow paragraphs
          This API creates short-form videos with AI from YouTube videos. It uses OpenAI to create 60 seconds videos from YouTube links with one click that can be shared on TikTok, Instagram, YouTube shorts, or more. The motivation behind this project was to familiarize myself with microservice architecture design and implementation. I learned how to create an scalable system by working with databases, messaging protocols, docker containers, Linux infrastructures, etc.
          ![alt text](images/microservice.jpg "shortube project")

  
  - title: Papers # Title for the section
    layout: list # Type of content section (list/text)
    content:
      - layout: left #top-middle
        title: Understanding Layer-Normalized Federated Learning under Extreme Label Shift
        link: https://arxiv.org/pdf/2308.09565.pdf
        sub_title: Under review
        link_text: Link to the paper
        additional_links:
          # - title:  
          #   icon: fab fa-github
          #   url: 
        #quote: >
          #This is probably one of the greatest apps ever created, if you don't agree you're probably wrong.
        description: | # this will include new lines to allow paragraphs
          Recently, layer normalization (LN) has been shown to be surprisingly effective in federated learning (FL) with non-i.i.d. data. However, exactly why and how it works remains mysterious. To understand layer normalization better in FL, we identify the key contributing mechanism of normalization methods in FL, called feature normalization (FN), which applies normalization to the latent feature representation before the classifier head. Although LN and FN do not improve expressive power, they control feature collapse and local overfitting to heavily skewed datasets, and thus accelerates global training. 
        
          ![alt text](images/normalization_table.PNG "Normalization Paper")

      - layout: left #top-middle
        title: Federated Learning Over Wireless Networks -- Challenges and Solutions
        link: https://ieeexplore.ieee.org/abstract/document/10153432
        sub_title: Internet of Things Journal
        link_text: Link to the paper
        additional_links:
        #   - title:  
        #     icon: fab fa-github
        #     url: 
        #quote: >
          #This is probably one of the greatest apps ever created, if you don't agree you're probably wrong.
        description: | # this will include new lines to allow paragraphs
          In this survey, we discuss each of the challenges of deploying federated learning over wireless networks and their respective state-of-the-art proposed solutions in an in-depth manner. By illustrating the tradeoff between each of the solutions, we discuss the underlying effect of the wireless network on the performance of FL.
          
          ![alt text](images/class.png "Survey Paper")

      - layout: left #top-middle
        title: Dynamic Sparsification for Federated Learning (DSFL)
        link: https://ieeexplore.ieee.org/abstract/document/10019204/
        sub_title: ICCSPA 2022
        link_text: Link to the paper
        additional_links:
          - title:  hi
            icon: fab fa-github
            url: github.com/mahdibeit/DSFL

          # - title:  Github page for project (eg. sproogen/modern-resume-theme)
          #   icon: fab fa-github
          #   url: Link to project (eg. sproogen.github.io/modern-resume-theme)
        #quote: >
          #This is probably one of the greatest apps ever created, if you don't agree you're probably wrong.
        description: | # this will include new lines to allow paragraphs
          In this paper, we introduce a novel Dynamic Sparsification for Federated Learning (DSFL) approach that enables users to compress their local models based on their communication capacity at each iteration by using two novel sparsification methods: layer-wise similarity sparsification (LSS) and extended top-K sparsification. LSS enables DSFL to utilize the global redundant information in usersâ€™ models by using the Centralized Kernel Alignment (CKA) similarity for sparsification. 
          
          ![alt text](images/CKA.JPG "FLAC Project")
    
    
      - layout: left #top-middle
        title: Federated Learning with Autoencoder Compression (FLAC)
        link: https://ieeexplore.ieee.org/abstract/document/10000743/
        sub_title: IEEE GLOBECOM 2022
        link_text: Link to the paper
        additional_links:
          - title:  github.com/mahdibeit/FLAC
            icon: fab fa-github
            url: github.com/mahdibeit/FLAC
            
          # - title:  Github page for project (eg. sproogen/modern-resume-theme)
          #   icon: fab fa-github
          #   url: Link to project (eg. sproogen.github.io/modern-resume-theme)
        #quote: >
          #This is probably one of the greatest apps ever created, if you don't agree you're probably wrong.
        description: | # this will include new lines to allow paragraphs
          In this paper, we propose the Federated Learning with Autoencoder Compression (FLAC) approach that utilizes the redundant information and error-correcting capability of Federated Learning (FL) to compress user devices' models for uplink transmission. FLAC trains an autoencoder to encode and decode users' models at the server in the Training State, and then, sends the autoencoder to user devices for compressing local models for future iterations during the Compression State. We theoretically prove that FLAC converges for FL systems with strongly convex ML models and non-i.i.d. data distribution.
          
          ![alt text](images/FLAC.jpg "FLAC Project")
          
          
      - layout: left #top-middle
        title: Crowd Counting with Perceptual Loss Function
        link: github.com/mahdibeit/Crowd-Counting
        #sub_title: Submitted to IEEE GLOBECOM 2022
        # link_text: Project Website
        additional_links:
          - title:  github.com/mahdibeit/Crowd-Counting
            icon: fab fa-github
            url: github.com/mahdibeit/Crowd-Counting
            
          # - title:  Github page for project (eg. sproogen/modern-resume-theme)
          #   icon: fab fa-github
          #   url: Link to project (eg. sproogen.github.io/modern-resume-theme)
        #quote: >
          #This is probably one of the greatest apps ever created, if you don't agree you're probably wrong.
        description: | # this will include new lines to allow paragraphs
          This project aims to develop, analyze, and evaluate methods that can accurately estimate the crowd count from a single image-based and generate the density map of images. To this end, we propose novel ideas in three main parts of preprocessing, model architectures, and loss function of our deep learning pipeline. More specifically, we utilize transfer learning methods by using pre-trained depth and image models to develop depth-guided attention models and VGG-based U-Net architecture to address the limited number of samples in the dataset and increase the accuracy.
         
          ![alt text](images/Crowd.jpg "Crowd Project")
          
          
      - layout: left #top-middle
        title: EEG-Based Brain Computer Interface
        link: https://github.com/mahdibeit/EEG-BasedBCI
        #sub_title: Submitted to IEEE GLOBECOM 2022
        # link_text: Project Website
        additional_links:
          - title:  https://github.com/mahdibeit/EEG-BasedBCI
            icon: fab fa-github
            url: https://github.com/mahdibeit/EEG-BasedBCI

          # - title:  Github page for project (eg. sproogen/modern-resume-theme)
          #   icon: fab fa-github
          #   url: Link to project (eg. sproogen.github.io/modern-resume-theme)
        #quote: >
          #This is probably one of the greatest apps ever created, if you don't agree you're probably wrong.
        description: | # this will include new lines to allow paragraphs
          In this project, we utilized Spatio-temporal Representation Learning for EEG-based Brain-Computer Interfaces. We propose a novel method that can capture spatio-temporal representations of raw EEG in commercial settings using autoencoders. More specifically, we modify the machine learning (ML) pipeline by adding a feature learning preprocessing method that can capture cross-subject informationIn this project, we utilize Pytorch to build an end-to-end classification pipeline for Motor Imagery (MI) tasks using cross-subject data.

          ![alt text](images/BCI.jpg "BCI Project")



  
  - title: Programming Languages and Libraries
    layout: text
    content: | # this will include new lines to allow paragraphs
      Programming languages: <mark>Python</mark>, <mark>C</mark>, <mark>Matlab</mark>, <mark>SQL</mark>, <mark>Java</mark>, <mark>Bash</mark>, <mark>Git</mark>
      
      Libraries: <mark>Python</mark>,  <mark>PyTorch</mark>, <mark>Pandas</mark>, <mark>Tensorflow</mark>, <mark>Flower</mark>, <mark>PySyft</mark>, <mark>Numpy</mark>, <mark>CUDA</mark>, <mark>Sklearn</mark>, <mark>Keras</mark>, <mark>SciPy</mark>, <mark>XGBoost</mark>, <mark>Matplotlib</mark>, <mark>PySpark</mark>, <mark>MLflow</mark>

# Footer
footer_show_references: true
# references_title: References on request (Override references text)

# Build settings
remote_theme: sproogen/resume-theme

sass:
  sass_dir: _sass
  style: compressed

plugins:
 - jekyll-seo-tag
